# Math for Machine learning with python
From formula to python codes.

This repository concentrates on how to translate formula commonly found in papers (focused ML, AI and DL) into a python code. The focus is not on how to build a fully fledged method/algorithm but rather how to implement its building blocks. As an example: *rather thank showing you how to build an entire DL framework, this repository will show how to code a ReLu activation function instead*. Most of the articles will be implemented in a python notebook as it offers the best way to combine comments, codes and plotting.

A nice blog article can be found [here](https://towardsdatascience.com/the-mathematics-of-machine-learning-894f046c568)

## Linear Algebra
Some topics such as Principal Component Analysis (PCA), Singular Value Decomposition (SVD), Eigendecomposition of a matrix, LU Decomposition, QR Decomposition/Factorization, Symmetric Matrices, Orthogonalization & Orthonormalization, Matrix Operations, Projections, Eigenvalues & Eigenvectors, Vector Spaces and Norms are needed for understanding the optimization methods used for machine learning.

## Probability Theory and Statistics
Combinatorics, Probability Rules & Axioms, Bayesâ€™ Theorem, Random Variables, Variance and Expectation, Conditional and Joint Distributions, Standard Distributions (Bernoulli, Binomial, Multinomial, Uniform and Gaussian), Moment Generating Functions, Maximum Likelihood Estimation (MLE), Prior and Posterior, Maximum a Posteriori Estimation (MAP) and Sampling Methods.

## Multivariate Calculus:
Differential and Integral Calculus, Partial Derivatives, Vector-Values Functions, Directional Gradient, Hessian, Jacobian, Laplacian and Lagrangian Distribution.

## Algorithms and Complexity
This is important for understanding the computational efficiency and scalability of our Machine Learning Algorithm and for exploiting sparsity in our datasets. Knowledge of data structures (Binary Trees, Hashing, Heap, Stack etc), Dynamic Programming, Randomized & Sublinear Algorithm, Graphs, Gradient/Stochastic Descents and Primal-Dual methods are needed.


TBD 
[link #1](https://machinelearningmastery.com/implement-machine-learning-algorithm-performance-metrics-scratch-python/)
[Frechet Inception Distance (FID)](https://machinelearningmastery.com/how-to-implement-the-frechet-inception-distance-fid-from-scratch/)
[Inception Score (IS)](https://machinelearningmastery.com/how-to-implement-the-inception-score-from-scratch-for-evaluating-generated-images/)
[Wasserstein Loss](https://machinelearningmastery.com/how-to-implement-wasserstein-loss-for-generative-adversarial-networks/)
